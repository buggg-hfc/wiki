---
comments: true
---

# 绪论

## 数据结构

### 基础概念及术语

1. `数据`：是描述客观事物的符号，是计算机中可以操作的对象，是能被计算机识别，并输入给计算机处理的符号集合
2. `数据元素`：是组成数据的、有一定意义的 **基本单位**，在计算机中通常作为整体处理，也被称为记录
3. `数据项`：一个数据元素可以由若干个数据项组成，数据项是不可分割的 **最小单位**
4. `数据对象`：是性质相同的数据元素的集合，是数据的子集
5. `数据结构`：是相互之间存在一种或多种特定关系的数据元素的集合

### 逻辑结构与物理结构

- `逻辑结构`：是指数据对象中数据元素之间的相互关系，分为如下四类：

|   类别   |                             特点                             |
| :------: | :----------------------------------------------------------: |
| 集合结构 | 集合结构中的数据元素除了同属于一个集合外，它们之间 **没有其他关系** |
| 线性结构 |         线性结构中的数据元素之间是 **一对一** 的关系         |
| 树形结构 |    树形结构中的数据元素之间存在一种 **一对多** 的层次关系    |
| 图状结构 |            图形结构的数据元素是 **多对多** 的关系            |

???+ note "提示"
    用示意图表示数据的逻辑结构时通常将每一个 **数据元素** 看作一个结点

- `物理结构`：是指数据的逻辑结构在计算机中的存储形式，分为如下两类：

|     类别     |                             描述                             |
| :----------: | :----------------------------------------------------------: |
| 顺序存储结构 | 把数据元素存放在地址连续的存储单元里，其数据间的逻辑关系和物理关系是一致的，即顺序映像 |
| 链式存储结构 | 把数据元素存放在任意的存储单元里，这组存储单元可以是连续的，也可以是不连续的，即非顺序映像 |

???+ note "总结"
    逻辑结构是 **面向问题** 的，物理结构是 **面向计算机** 的

### 数据类型与抽象数据类型

- `数据类型`：是指一组性质相同的值的集合及定义在此集合上的一些操作的总称
- `抽象数据类型(ADT)`：一个数学模型及定义在该模型上的一组操作，有两个重要特征：**数据抽象** 和 **数据封装**

## 算法

### 算法的定义

- `算法`：是解决特定问题求解步骤的描述，在计算机中表现为指令的有限序列，并且每条指令表示一个或多个操作

### 算法的特性

1. `有穷性`：算法在执行有限的步骤之后，自动结束而不会出现无限循环，并且每一个步骤在可接受的时间内完成
2. `确定性`：算法的每一步都具有确定的含义，不会出现二义性
3. `可行性`：算法的每一步都必须是可行的，也就是说，每一步都能通过执行有限次数完成
4. `输入`：算法有零个或多个输入
5. `输出`：算法有一个或多个输出

### 算法设计的要求

1. `正确性`：算法至少应该具有输入、输出和加工处理无歧义性，能正确反映问题的需求，能够得到问题的正确答案
2. `可读性`：算法设计的另一目的是为了便于阅读、理解和交流
3. `健壮性`：当输入数据不合法时，算法也能做出相关处理，而不是产生异常或莫名其妙的结果
4. `时间效率高和存储量低`：设计算法应该尽量满足时间效率高和存储量低的需求

### 算法的性能分析与度量

要对一个算法做出全面的分析通常有以下两种方法：

|       方法       |                             描述                             |
| :--------------: | :----------------------------------------------------------: |
|   事后统计方法   | 通过设计好的测试程序和数据，利用计算机计时器对不同算法编制的程序的运行时间进行比较，从而确定算法效率的高低 |
| 事前分析估算方法 |        在计算机程序编制前，依据统计方法对算法进行估算        |

经过分析，我们发现，一个用高级程序语言编写的程序在计算机上运行时所消耗的时间取决于下列四种因素：

1. 算法采用的策略、方法
2. 编译产生的代码质量
3. 问题的输入规模
4. 机器执行指令的速度

第 $1$ 条是算法好坏的根本，第 $2$ 条要由软件来支持，第 $4$ 条要看硬件性能。也就是说，抛开这些与计算机硬件、软件有关的因素，**一个程序的运行时间，依赖于算法的好坏和问题的输入规模，即输入量的多少**

### 函数的渐近增长

- `函数的渐近增长`：给定两个函数 $f(n)$ 和 $g(n)$，如果存在一个整数 $N$，使得对于所有的 $n>N$，$f(n)$ 总是比 $g(n)$ 大，那么，我们说 $f(n)$ 的增长渐近快于 $g(n)$
- 可以忽略加法常数
- 可以忽略与最高次项相乘的常数
- 可以忽略除最高次项外的项

???+ note "总结"
    判断一个算法的效率时，函数中的常数和其他次要项一般可以忽略，而更应该关注主项（最高阶项）的阶数

### 算法时间复杂度

- `时间复杂度`：记作 $T(n)=O(f(n))$，表示随问题规模 $n$ 的增大，算法执行时间的增长率和 $f(n)$ 的增长率相同，这样用大写 $O()$ 来体现时间复杂度的记法称为 `大O记法`
- 推导大O阶：
    1. 用常数 $1$ 取代运算时间中的所有加法常数
    2. 在修改后的运行次数函数中，只保留最高阶项
    3. 如果最高阶项存在且其系数不是 $1$，则去除与这个项相乘的系数，得到的结果就是大O阶

常见阶（按时间复杂度排序）：

|         执行次数函数         |     阶     | 非正式术语 |
| :--------------------------: | :--------: | :--------: |
|             $12$             |    $1$     |   常数阶   |
|        $5log_{2}n+20$        | $O(logn)$  |   对数阶   |
|            $2n+3$            |   $O(n)$   |   线性阶   |
|      $2n+3nlog_{2}n+19$      | $O(nlogn)$ | 线性对数阶 |
|        $3n^{2}+2n+1$         | $O(n^{2})$ |   平方阶   |
|     $6n^{3}+2n^{2}+3n+4$     |  $O(n^3)$  |   立方阶   |
|           $2^{n}$            | $O(2^{n})$ |   指数阶   |
|        $\frac{n!}{2}$        |  $O(n!)$   |   阶乘阶   |
| $\frac{1}{3}n^{\frac{n}{4}}$ | $O(n^{n})$ | $n$ 次幂阶 |



### 算法空间复杂度

`空间复杂度`：记作 $S(n)=O(f(n))$

## 拓展

### 递归函数的时间复杂度

我们可以使用主定理 (Master Theorem) 来快速求得关于递归算法的复杂度

Master Theorem 递推关系式如下

$$
T(n) = a T\left(\frac{n}{b}\right)＋f(n)\qquad \forall n > b
$$

那么

$$
T(n) = \begin{cases}\Theta(n^{\log_b a}) & f(n) = O(n^{\log_b a-\epsilon}) \\ \Theta(f(n)) & f(n) = \Omega(n^{\log_b a+\epsilon})\\ \Theta(n^{\log_b a}\log^{k+1} n) & f(n)=\Theta(n^{\log_b a}\log^k n),k\ge 0 \end{cases}
$$

需要注意的是，这里的第二种情况还需要满足 regularity condition, 即 $a f(n/b) \leq c f(n)$，for some constant $c < 1$ and sufficiently large $n$。

证明思路是是将规模为 $n$ 的问题，分解为 $a$ 个规模为 $(\frac{n}{b})$ 的问题，然后依次合并，直到合并到最高层。每一次合并子问题，都需要花费 $f(n)$ 的时间。

??? note "证明"
    依据上文提到的证明思路，具体证明过程如下
    
    对于第 $0$ 层（最高层），合并子问题需要花费 $f(n)$ 的时间
    
    对于第 $1$ 层（第一次划分出来的子问题），共有 $a$ 个子问题，每个子问题合并需要花费 $f\left(\frac{n}{b}\right)$ 的时间，所以合并总共要花费 $a f\left(\frac{n}{b}\right)$ 的时间。
    
    层层递推，我们可以写出类推树如下：![](./images/master-theorem-proof.svg)
    
    这棵树的高度为 ${\log_b n}$，共有 $n^{\log_b a}$ 个叶子，从而 $T(n) = \Theta(n^{\log_b a}) + g(n)$，其中 $g(n) = \sum_{j = 0}^{\log_{b}{n - 1}} a^{j} f(n / b^{j})$。
    
    针对于第一种情况：$f(n) = O(n^{\log_b a-\epsilon})$，因此 $g(n) = O(n^{\log_b a})$。
    
    对于第二种情况而言：首先 $g(n) = \Omega(f(n))$，又因为 $a f(\dfrac{n}{b}) \leq c f(n)$，只要 $c$ 的取值是一个足够小的正数，且 $n$ 的取值足够大，因此可以推导出：$g(n) = O(f(n)$)。两侧夹逼可以得出，$g(n) = \Theta(f(n))$。
    
    而对于第三种情况：$f(n) = \Theta(n^{\log_b a})$，因此 $g(n) = O(n^{\log_b a} {\log n})$。$T(n)$ 的结果可在 $g(n)$ 得出后显然得到。

下面举几个例子来说明主定理如何使用。

例如 $T(n) = 3 T\left(\frac{n}{2}\right) + 2n$，那么 $a=3, b=2, 1< {\log_2 3} <2$，那么 $\epsilon$ 可以取值为 $1$，从而满足第一种情况，所以 $T(n) = \Theta(n^2)$。

又例如 $T(n) = T\left(\frac{n}{2}\right) + n$，那么 $a=1, b=2, {\log_2 1} = 0$，那么 $\epsilon$ 可以取值为 $0.5$，从而满足第二种情况，所以 $T(n) = \Theta(n)$。

再例如 $T(n) = T\left(\frac{n}{2}\right) + {\log n}$，那么 $a=1, b=2, {\log_2 1}=0$，那么 $k$ 可以取值为 $1$，从而满足第三种情况，所以 $T(n) = \Theta(\log^2 n)$。
